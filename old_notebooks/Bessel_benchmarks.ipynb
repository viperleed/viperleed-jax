{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "from jax.scipy.special import sph_harm\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "import scipy\n",
    "import timeit\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Spherical Bessel functions from NeuralIL\n",
    "from otftleed.spherical_bessel import functions\n",
    "\n",
    "# numerical epsilon to avoid division by zero\n",
    "EPS = 1e-8\n",
    "bessel_EPS = 10e-7\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bessel_scipy(z, n1, derivative=False):\n",
    "    return scipy.special.spherical_jn(np.arange(n1), z, derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bessel_tenserleed(Z, N1):\n",
    "    BJ = []\n",
    "    # Initialize complex variables\n",
    "    ZSQ = Z**2 / 2.0\n",
    "\n",
    "    # L is indeed the angular momentum in question.\n",
    "\n",
    "    # L dependent prefactor\n",
    "    PRE = 1.0 + 0j\n",
    "\n",
    "    for L in range(N1):\n",
    "        # K is index of series expansion.\n",
    "\n",
    "        def body_fun(args):\n",
    "            K, TERM, SUM = args\n",
    "            TERM = -ZSQ / (K * (2 * L + 2 * K + 1)) * TERM\n",
    "            SUM = SUM + TERM\n",
    "            return K + 1, TERM, SUM\n",
    "        # Repeat the loop until TERM is really small\n",
    "        def cond_fun(args):\n",
    "            K, TERM, SUM = args\n",
    "            return abs(TERM) > 1e-16\n",
    "        K, TERM, SUM = jax.lax.while_loop(cond_fun,\n",
    "                           body_fun, (1.0, 1.0+0j, 1.0+0j))\n",
    "\n",
    "\n",
    "        # Evaluate j_L(Z), i.e., BJ[L]\n",
    "        BJ.append((PRE * SUM))\n",
    "\n",
    "        # Update PRE for the next L\n",
    "        PRE *= Z / (2.0 * (L + 1) + 1.0)\n",
    "    return jnp.asarray(BJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax import jit\n",
    "from functools import partial\n",
    "\n",
    "from jax.scipy.special import gamma\n",
    "\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)  \n",
    "\n",
    "\n",
    "from jax._src.lax import lax\n",
    "from jax._src.typing import Array, ArrayLike\n",
    "from jax._src.numpy.util import (\n",
    "   check_arraylike, promote_dtypes_inexact, _where)\n",
    "from jax._src.custom_derivatives import custom_jvp\n",
    "\n",
    "_lax_const = lax._const\n",
    "\n",
    "def jint(n):\n",
    "    return jnp.trunc(n).astype('int')\n",
    "\n",
    "def spb1(x: ArrayLike, /) -> Array:\n",
    "    '''\n",
    "    Calculate the spherical Bessel functions j_1(z). \n",
    "    Follows existing implementation of jnp.sinc for safety around 0, \n",
    "    using a Maclaurin series to keep continuous derivatives.\n",
    "\n",
    "    Arguments:\n",
    "        x: The argument of the function.\n",
    "\n",
    "    Returns:\n",
    "        csj: The function j_1(z).\n",
    "    '''\n",
    "\n",
    "    check_arraylike(\"spb1\", x)\n",
    "    x, = promote_dtypes_inexact(x)\n",
    "\n",
    "    # not defined at zero\n",
    "    eq_zero = lax.eq(x, _lax_const(x, 0))\n",
    "    \n",
    "    safe_x = _where(eq_zero, _lax_const(x, 1), x)\n",
    "    return _where(eq_zero, _spb1_maclaurin(0, x),\n",
    "                    lax.div(lax.sin(safe_x), safe_x**2)-lax.div(lax.cos(safe_x), safe_x))\n",
    "\n",
    "@partial(custom_jvp, nondiff_argnums=(0,))\n",
    "def _spb1_maclaurin(k, x):\n",
    "  # compute the kth derivative of x -> sin(x)/x evaluated at zero (since we\n",
    "  # compute the monomial term in the jvp rule)\n",
    "  # TODO(mattjj): see https://github.com/google/jax/issues/10750\n",
    "  if k % 2:\n",
    "    return x * 0\n",
    "  else:\n",
    "    top = 1.j* (1.j/2)**k * jnp.sqrt(jnp.pi)\n",
    "    bottom = (k-1) * gamma(2+k/2) * gamma(0.5*(k-1))\n",
    "    return x * 0 + jnp.real(top / bottom)\n",
    "\n",
    "@_spb1_maclaurin.defjvp\n",
    "def _spb1_maclaurin_jvp(k, primals, tangents):\n",
    "  (x,), (t,) = primals, tangents\n",
    "  return _spb1_maclaurin(k, x), _spb1_maclaurin(k + 1, x) * t\n",
    "\n",
    "\n",
    "def envj(n, x):\n",
    "    '''\n",
    "    Helper function for msta1 and msta2.\n",
    "\n",
    "    '''\n",
    "    envj = 0.5 * jnp.log10(6.28 * n) - n * jnp.log10(1.36 * x / n) # always true \n",
    "\n",
    "    return envj\n",
    "\n",
    "def msta1(x, mp):\n",
    "    ''' \n",
    "    Calculate the number of terms required for the spherical Bessel function.\n",
    "    '''\n",
    "    a0 = jnp.abs(x)\n",
    "    n0 = jint(1.1 * a0) + 1\n",
    "    f0 = envj(n0, a0) - mp\n",
    "    n1 = n0 + 5\n",
    "    f1 = envj(n1, a0) - mp\n",
    "\n",
    "    nn = jint(n1 - (n1 - n0) / (1.0 - f0 / f1))\n",
    "    f = envj(nn, a0) - mp\n",
    "    n0 = n1\n",
    "    f0 = f1\n",
    "    n1 = nn\n",
    "    f1 = f\n",
    "    diff = jnp.abs(nn - n1)\n",
    "\n",
    "    def cond_fun(inputs):\n",
    "        n0, f0, n1, f1, nn, counter, diff = inputs\n",
    "        return jnp.logical_and(jnp.abs(diff) > 1, counter < 20)\n",
    "\n",
    "    def body_fun(inputs):\n",
    "        n0, f0, n1, f1, nn, diff, counter = inputs\n",
    "        nn = jint(n1 - (n1 - n0) / (1.0 - f0 / f1))\n",
    "        diff = nn - n1\n",
    "        f = envj(nn, a0) - mp\n",
    "        n0 = n1\n",
    "        f0 = f1\n",
    "        n1 = nn\n",
    "        f1 = f\n",
    "        counter += 1\n",
    "        return n0, f0, n1, f1, nn, diff, counter\n",
    "\n",
    "    n0, f0, n1, f1, nn, diff, _ = jax.lax.while_loop(cond_fun, body_fun, (n0, f0, n1, f1, nn, diff, 0))\n",
    "\n",
    "    return nn\n",
    "\n",
    "def msta2(x, n, mp):\n",
    "    ''' \n",
    "    Calculate the number of terms required for the spherical Bessel function.\n",
    "    '''\n",
    "    a0 = jnp.abs(x)\n",
    "    hmp = 0.5 * mp\n",
    "    ejn = envj(n, a0)\n",
    "\n",
    "    obj, n0 = jax.lax.cond(ejn <= hmp, \n",
    "                       lambda _: (mp*1.0, jint(1.1 * a0) + 1), \n",
    "                       lambda _: (hmp + ejn, jint(n)), \n",
    "                       operand=None)\n",
    "\n",
    "    f0 = envj(n0, a0) - obj\n",
    "    n1 = n0 + 5\n",
    "    f1 = envj(n1, a0) - obj\n",
    "\n",
    "    nn = jint(n1 - (n1 - n0) / (1.0 - f0 / f1))\n",
    "\n",
    "    def cond_fun(inputs):\n",
    "        n0, f0, n1, f1, nn, diff, counter = inputs\n",
    "        return jnp.logical_and(jnp.abs(diff) >= 1, counter < 20)\n",
    "\n",
    "    def body_fun(inputs):\n",
    "        n0, f0, n1, f1, nn, diff, counter = inputs\n",
    "        nn = jint(n1 - (n1 - n0) / (1.0 - f0 / f1))\n",
    "        diff = nn - n1\n",
    "        f = envj(nn, a0) - obj\n",
    "        n0 = n1\n",
    "        f0 = f1\n",
    "        n1 = nn\n",
    "        f1 = f\n",
    "        counter += 1\n",
    "        return n0, f0, n1, f1, nn, diff, counter\n",
    "    \n",
    "    n0, f0, n1, f1, nn, diff, _ = jax.lax.while_loop(cond_fun, body_fun, (n0, f0, n1, f1, nn, nn-n1, 0))\n",
    "\n",
    "    return nn + 10\n",
    "\n",
    "@partial(custom_jvp, nondiff_argnums=(0,))\n",
    "@partial(jit,static_argnums=0)\n",
    "def csphjy(n, z):\n",
    "    ''' \n",
    "    Spherical Bessel functions of the first and second kind, and their derivatives.\n",
    "    Follows the implementation of https://github.com/emsr/maths_burkhardt/blob/master/special_functions.f90, but with the derivatives.\n",
    "    Arguments:\n",
    "        n: The order of the spherical Bessel function.\n",
    "        z: The argument of the function.    \n",
    "    Returns:\n",
    "        nm: The number of terms used in the calculation.\n",
    "        csj: The function j_n(z).\n",
    "        cdj: The derivative of the function j_n(z).\n",
    "        csy: The function y_n(z).\n",
    "        cdy: The derivative of the function y_n(z).\n",
    "        \n",
    "    '''\n",
    "    a0 = jnp.abs(z)\n",
    "    nm = n\n",
    "    complex = jax.dtypes.canonicalize_dtype(jnp.complex128)\n",
    "    csj = jnp.zeros(n+1, dtype=complex)\n",
    "    csj = csj.at[0].set(jnp.sinc(z /jnp.pi))\n",
    "    csj = csj.at[1].set(spb1(z))\n",
    "\n",
    "    if n >= 2:\n",
    "        csa = csj[0]\n",
    "        csb = csj[1]\n",
    "        m = msta1(a0, 200)\n",
    "\n",
    "        m, nm = jax.lax.cond(m < n, \n",
    "                     lambda _: (m, m), \n",
    "                     lambda _: (msta2(a0, n, 15), n), \n",
    "                     operand=None)\n",
    "\n",
    "        cf0 = jnp.asarray(0.0, dtype=z)\n",
    "        cf1 = jnp.asarray(1.0e-100, dtype=z)\n",
    "        cf = (2.0 * m + 3.0) * cf1 / z - cf0\n",
    "\n",
    "        def body_fun(kk, inputs):\n",
    "            k = m - kk\n",
    "            cf, csj, cf0, cf1 = inputs\n",
    "            cf = (2.0 * k + 3.0) * cf1 / z - cf0\n",
    "            def true_fun(csj):\n",
    "                return csj.at[k].set(cf)\n",
    "            csj = jax.lax.cond(k <= nm, true_fun, lambda csj: csj, csj)\n",
    "            cf0 = cf1\n",
    "            cf1 = cf\n",
    "            return cf, csj, cf0, cf1\n",
    "\n",
    "        cf, csj, cf0, cf1 = jax.lax.fori_loop(0, m+1, body_fun, (cf, csj, cf0, cf1))\n",
    "\n",
    "        cs = jax.lax.cond(jnp.abs(csa) <= jnp.abs(csb), \n",
    "                  lambda _: csb / cf0, \n",
    "                  lambda _: csa / cf, \n",
    "                  operand=None)\n",
    "        \n",
    "\n",
    "        csj = cs * csj\n",
    "\n",
    "    return csj\n",
    "\n",
    "@csphjy.defjvp\n",
    "def csphjy_jvp(n, primals, tangents):\n",
    "    z, = primals\n",
    "    z_dot, = tangents\n",
    "    csj = csphjy(n,z)\n",
    "    \n",
    "    cdj = jnp.zeros(n+1, dtype=complex)\n",
    "    cdj = cdj.at[0].set((jnp.cos(z) - jnp.sin(z) / z) / z)\n",
    "    cdj = cdj.at[1:].set(csj[:-1] - (jnp.arange(1, len(csj)) + 1.0) * csj[1:] / z)\n",
    "    return csj, cdj*z_dot\n",
    "\n",
    "\n",
    "def maketriples_all(mask,verbose=False):\n",
    "    \"\"\" returns int array of triple hole indices (0-based), \n",
    "        and float array of two uv vectors in all triangles\n",
    "    \"\"\"\n",
    "    nholes = mask.shape[0]\n",
    "    tlist = []\n",
    "    for i in range(nholes):\n",
    "        for j in range(nholes):\n",
    "            for k in range(nholes):\n",
    "                if i < j and j < k:\n",
    "                    tlist.append((i, j, k))\n",
    "    tarray = np.array(tlist).astype(np.int32)\n",
    "    if verbose:\n",
    "        print(\"tarray\", tarray.shape, \"\\n\", tarray)\n",
    "\n",
    "    tname = []\n",
    "    uvlist = []\n",
    "    # foreach row of 3 elts...\n",
    "    for triple in tarray:\n",
    "        tname.append(\"{0:d}_{1:d}_{2:d}\".format(\n",
    "            triple[0], triple[1], triple[2]))\n",
    "        if verbose:\n",
    "            print('triple:', triple, tname[-1])\n",
    "        uvlist.append((mask[triple[0]] - mask[triple[1]],\n",
    "                       mask[triple[1]] - mask[triple[2]]))\n",
    "    # print(len(uvlist), \"uvlist\", uvlist)\n",
    "    if verbose:\n",
    "        print(tarray.shape, np.array(uvlist).shape)\n",
    "    return tarray, np.array(uvlist)\n",
    "\n",
    "def makebaselines(mask):\n",
    "    \"\"\"\n",
    "    ctrs_eqt (nh,2) in m\n",
    "    returns np arrays of eg 21 baselinenames ('0_1',...), eg (21,2) baselinevectors (2-floats)\n",
    "    in the same numbering as implaneia\n",
    "    \"\"\"\n",
    "    nholes = mask.shape[0]\n",
    "    blist = []\n",
    "    for i in range(nholes):\n",
    "        for j in range(nholes):\n",
    "            if i < j:\n",
    "                blist.append((i, j))\n",
    "    barray = np.array(blist).astype(np.int32)\n",
    "    # blname = []\n",
    "    bllist = []\n",
    "    for basepair in blist:\n",
    "        # blname.append(\"{0:d}_{1:d}\".format(basepair[0],basepair[1]))\n",
    "        baseline = mask[basepair[0]] - mask[basepair[1]]\n",
    "        bllist.append(baseline)\n",
    "    return barray, np.array(bllist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum order of spherical Bessel functions needed for the calculation\n",
    "max_order = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar test\n",
    "z = 2.0 + 3.0j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real valued test array\n",
    "z = np.linspace(1e-100, 10, 1000)\n",
    "\n",
    "# complex valued test array\n",
    "z = z + 1j * z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonix\n",
    "bessel_harmonix = jax.jit(csphjy, static_argnums=0)\n",
    "bessel_harmonix_v = jax.jit(jax.vmap(csphjy, in_axes=(None,0)), static_argnums=0)\n",
    "bessel_harmonix_jac = jax.jit(jax.jacrev(csphjy, argnums=1, holomorphic=True), static_argnums=0)\n",
    "bessel_harmonix_v_jac = jax.jit(jax.vmap(bessel_harmonix_jac, in_axes=(None,0)), static_argnums=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensErLEED Series expansion\n",
    "bessel_tenserleed = jax.jit(bessel_tenserleed, static_argnums=1)\n",
    "bessel_tenserleed_v = jax.jit(jax.vmap(bessel_tenserleed, in_axes=(0,None)), static_argnums=1)\n",
    "bessel_tenserleed_jac = jax.jit(jax.jacfwd(bessel_tenserleed, argnums=0, holomorphic=True), static_argnums=1)\n",
    "bessel_tenserleed_v_jac = jax.jit(jax.vmap(bessel_tenserleed_jac, in_axes=(0,None)), static_argnums=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_bessel_functions(l_max):\n",
    "    \"\"\"Generate a list of spherical Bessel functions up to order l_max\"\"\"\n",
    "    bessel_functions = []\n",
    "    for order in range(l_max+1):\n",
    "        bessel_functions.append(jax.jit(functions.create_j_l(order)))\n",
    "    return bessel_functions\n",
    "\n",
    "\n",
    "# generate a list of spherical Bessel functions up to order l_max\n",
    "BESSEL_FUNCTIONS = _generate_bessel_functions(max_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuralIL Single L\n",
    "def bessel_neuralil_base(z, n1):\n",
    "    \"\"\"Spherical Bessel functions. Evaluated at z, up to degree n1.\"\"\"\n",
    "    return BESSEL_FUNCTIONS[n1](z)\n",
    "\n",
    "bessel_neuralil = jax.jit(bessel_neuralil_base, static_argnums=1)\n",
    "bessel_neuralil_v = jax.jit(jax.vmap(bessel_neuralil_base, in_axes=(0,None)), static_argnums=1)\n",
    "bessel_neuralil_jac = jax.jit(jax.jacrev(bessel_neuralil_base, argnums=0, holomorphic=True), static_argnums=1)\n",
    "bessel_neuralil_v_jac = jax.jit(jax.vmap(bessel_neuralil_jac, in_axes=(0,None)), static_argnums=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuralIL all L\n",
    "def bessel_neuralil_series_base(z, n1):\n",
    "    return jnp.asarray([BESSEL_FUNCTIONS[order](z) for order in range(n1)])\n",
    "\n",
    "bessel_neuralil_series = jax.jit(bessel_neuralil_series_base, static_argnums=1)\n",
    "bessel_neuralil_series_v = jax.jit(jax.vmap(bessel_neuralil_series_base, in_axes=(0,None)), static_argnums=1)\n",
    "bessel_neuralil_series_jac = jax.jit(jax.jacrev(bessel_neuralil_series_base, argnums=0, holomorphic=True), static_argnums=1)\n",
    "bessel_neuralil_series_v_jac = jax.jit(jax.vmap(bessel_neuralil_series_jac, in_axes=(0,None)), static_argnums=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_spherical_jn(n, z):\n",
    "    return jax.lax.switch(n, BESSEL_FUNCTIONS, z)\n",
    "\n",
    "def bessel_neuralil_select_base(z, n1):\n",
    "    \"\"\"Spherical Bessel functions. Evaluated at z, up to degree n1.\"\"\"\n",
    "    vmapped_custom_bessel = jax.vmap(custom_spherical_jn, (0, None))\n",
    "    return vmapped_custom_bessel(jnp.arange(n1), z)\n",
    "\n",
    "\n",
    "bessel_neuralil_select = jax.jit(bessel_neuralil_select_base, static_argnums=1)\n",
    "bessel_neuralil_select_v = jax.jit(jax.vmap(bessel_neuralil_select_base, in_axes=(0,None)), static_argnums=1)\n",
    "bessel_neuralil_select_jac = jax.jit(jax.jacrev(bessel_neuralil_select_base, argnums=0, holomorphic=True), static_argnums=1)\n",
    "bessel_neuralil_select_v_jac = jax.jit(jax.vmap(bessel_neuralil_select_jac, in_axes=(0,None)), static_argnums=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timinings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "def time_functions(z, suffix, max_order, n_repeats):\n",
    "    scipy_time = []\n",
    "    harmonix_time = []\n",
    "    neural_il_series_time = []\n",
    "    neural_il_select_time = []\n",
    "    neural_il_single_time = []\n",
    "    tenserleed_time = []\n",
    "    \n",
    "    z = repr(z)\n",
    "\n",
    "    for order in tqdm(range(1, max_order)):\n",
    "        derivative = 'jac' in suffix\n",
    "        scipy_time.append(\n",
    "            timeit.timeit(\n",
    "            f\"scipy.special.spherical_jn({order}, {z}, {derivative})\", globals=globals(),\n",
    "            number=n_repeats)/n_repeats\n",
    "        )\n",
    "\n",
    "        cmd = f\"bessel_neuralil_series{suffix}({z}, {order}).block_until_ready()\"\n",
    "        neural_il_series_time.append(\n",
    "            timeit.timeit(\n",
    "                cmd, globals=globals(), number=n_repeats)/n_repeats\n",
    "        )\n",
    "\n",
    "        cmd = f\"bessel_neuralil_select{suffix}({z}, {order}).block_until_ready()\"\n",
    "        neural_il_select_time.append(\n",
    "            timeit.timeit(\n",
    "                cmd, globals=globals(), number=n_repeats)/n_repeats\n",
    "        )\n",
    "\n",
    "        cmd = f\"bessel_neuralil{suffix}({z}, {order}).block_until_ready()\"\n",
    "        neural_il_single_time.append(\n",
    "            timeit.timeit(\n",
    "                cmd, globals=globals(), number=n_repeats)/n_repeats\n",
    "        )\n",
    "\n",
    "        cmd = f\"bessel_harmonix{suffix}({order}, {z}).block_until_ready()\"\n",
    "        harmonix_time.append(\n",
    "            timeit.timeit(\n",
    "                cmd, globals=globals(),number=n_repeats)/n_repeats\n",
    "        )\n",
    "\n",
    "        cmd = f\"bessel_tenserleed{suffix}({z}, {order}).block_until_ready()\"\n",
    "        tenserleed_time.append(\n",
    "            timeit.timeit(\n",
    "                cmd, globals=globals(),number=n_repeats)/n_repeats\n",
    "        )\n",
    "    return scipy_time, harmonix_time, neural_il_series_time, neural_il_select_time, neural_il_single_time, tenserleed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(times, ax, title=\"\"):\n",
    "    scipy_time, harmonix_time, neural_il_series_time, neural_il_select_time, neural_il_single_time, tenserleed_time = times\n",
    "    x = range(1, len(scipy_time)+1)\n",
    "\n",
    "#     plt.plot(x, scipy_time,\n",
    "#             ls='-', marker='s',\n",
    "#             label='scipy')\n",
    "    ax.plot(x, harmonix_time,\n",
    "            ls='-', marker='s',\n",
    "            label='harmonix')\n",
    "    ax.plot(x, neural_il_series_time,\n",
    "            ls='-', marker='s',\n",
    "            label='neural_il_series')\n",
    "    ax.plot(x, neural_il_select_time,\n",
    "            ls='-', marker='s',\n",
    "            label='neural_il_select')\n",
    "    ax.plot(x, neural_il_single_time,\n",
    "            ls='-', marker='s',\n",
    "            label='neural_il_single')\n",
    "    ax.plot(x, tenserleed_time,\n",
    "            ls='-', marker='s',\n",
    "            label='tenserleed')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scalar = 2.0 + 3.0j\n",
    "z_arr = np.linspace(1e-8, 2.0, 1000) + 1j*np.linspace(1e-8, 2.0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"\"\n",
    "\n",
    "# compile\n",
    "compile_times = time_functions(z_scalar, suffix, max_order, n_repeats=1)\n",
    "# execute\n",
    "times = time_functions(z_scalar, suffix, max_order, n_repeats=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"_v\"\n",
    "\n",
    "# compile\n",
    "compile_times_v = time_functions(z_arr, suffix, max_order, n_repeats=1)\n",
    "# execute\n",
    "times_v = time_functions(z_arr, suffix, max_order, n_repeats=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar-valued Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"_jac\"\n",
    "\n",
    "# compile\n",
    "compile_times_jac = time_functions(z_scalar, suffix, max_order, n_repeats=1)\n",
    "# execute\n",
    "times_jac = time_functions(z_scalar, suffix, max_order, n_repeats=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector-valued Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"_v_jac\"\n",
    "\n",
    "# compile\n",
    "compile_times_v_jac = time_functions(z_arr, suffix, max_order, n_repeats=1)\n",
    "# execute\n",
    "times_v_jac = time_functions(z_arr, suffix, max_order, n_repeats=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, sharex=True, figsize=(12,8))\n",
    "fig.suptitle('Compile time')\n",
    "fig.supxlabel('Order l')\n",
    "fig.supylabel('Time (s)')\n",
    "plot_results(compile_times, axs[0, 0], title=\"Scalar\")\n",
    "plot_results(compile_times_v, axs[0, 1], title=\"Vectorized\")\n",
    "plot_results(compile_times_jac, axs[1, 0], title=\"Scalar-valued Derivative\")\n",
    "plot_results(compile_times_v_jac, axs[1, 1], title=\"Vectorized Derivative\")\n",
    "fig.savefig(\"bessel_functions_compile_times.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, sharex=True, figsize=(12,8))\n",
    "fig.suptitle('Execution time')\n",
    "fig.supxlabel('Order l')\n",
    "fig.supylabel('Time (s)')\n",
    "plot_results(times, axs[0, 0], title=\"scalar valued argument\")\n",
    "plot_results(times_v, axs[0, 1], title=\"vector valued argument\")\n",
    "plot_results(times_jac, axs[1, 0], title=\"derivative for scalar valued argument\")\n",
    "plot_results(times_v_jac, axs[1, 1], title=\"derivative for vector valued argument\")\n",
    "fig.savefig(\"bessel_functions_execution_times.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(times[-2])/ np.array(times[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "def benchmark_functions(z, suffix, max_order):\n",
    "    harmonix_err = []\n",
    "    neuralil_err = []\n",
    "    tenserleed_err = []\n",
    "    \n",
    "    z = repr(z)\n",
    "\n",
    "    for order in tqdm(range(1, max_order)):\n",
    "        derivative = 'jac' in suffix\n",
    "        scipy_value = scipy.special.spherical_jn(order, z, derivative)\n",
    "\n",
    "        neuralil_err.append(\n",
    "            eval(f\"bessel_neuralil_series{suffix}({z}, {order}\")\n",
    "        )\n",
    "\n",
    "\n",
    "        harmonix_err.append(\n",
    "            eval(f\"bessel_harmonix{suffix}({order}, {z})\")\n",
    "        )\n",
    "\n",
    "        tenserleed_err.append(\n",
    "            eval(f\"bessel_tenserleed{suffix}({z}, {order})\")\n",
    "        )\n",
    "    return harmonix_err, neuralil_err, tenserleed_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonix_err = []\n",
    "neuralil_err = []\n",
    "tenserleed_err = []\n",
    "\n",
    "\n",
    "for order in tqdm(range(1, max_order)):\n",
    "    derivative = 'jac' in suffix\n",
    "    scipy_value = scipy.special.spherical_jn(order, z_arr, derivative)\n",
    "\n",
    "    neuralil_err.append(\n",
    "        np.max(abs(bessel_neuralil_series_v(z_arr, order)[:,order] - scipy_value))\n",
    "    )\n",
    "\n",
    "\n",
    "    harmonix_err.append(\n",
    "        np.max(abs(bessel_harmonix_v(order, z_arr)[:,order] - scipy_value))\n",
    "    )\n",
    "\n",
    "    tenserleed_err.append(\n",
    "        np.max(abs(bessel_tenserleed_v(z_arr, order)[:,order] - scipy_value))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonix_err_jac = []\n",
    "neuralil_err_jac = []\n",
    "tenserleed_err_jac = []\n",
    "\n",
    "\n",
    "for order in tqdm(range(1, max_order)):\n",
    "    derivative = 'jac' in suffix\n",
    "    scipy_value = scipy.special.spherical_jn(order, z_arr, derivative=True)\n",
    "\n",
    "    neuralil_err_jac.append(\n",
    "        np.max(abs(bessel_neuralil_series_v_jac(z_arr, order)[:,order] - scipy_value))\n",
    "    )\n",
    "\n",
    "\n",
    "    harmonix_err_jac.append(\n",
    "        np.max(abs(bessel_harmonix_v_jac(order, z_arr)[:,order] - scipy_value))\n",
    "    )\n",
    "\n",
    "    tenserleed_err_jac.append(\n",
    "        np.max(abs(bessel_tenserleed_v_jac(z_arr, order)[:,order] - scipy_value))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharex=True, figsize=(12,4))\n",
    "fig.suptitle(\"Error vs. Scipy\")\n",
    "\n",
    "fig.supxlabel('Order l')\n",
    "fig.supylabel('Deviation from Scipy')\n",
    "\n",
    "axs[0].set_title(\"Value\")\n",
    "axs[0].plot(harmonix_err, label='Harmonix', ls='-', marker = 's')\n",
    "axs[0].plot(neuralil_err, label='NeuralIL', ls='-', marker = 's')\n",
    "axs[0].plot(tenserleed_err, label='TensErLEED like expansion', ls='--', marker = 'o')\n",
    "axs[0].legend()\n",
    "axs[0].set_yscale('log')\n",
    "\n",
    "axs[1].set_title(\"Derivative\")\n",
    "axs[1].plot(harmonix_err_jac, label='Harmonix', ls='-', marker = 's')\n",
    "axs[1].plot(neuralil_err_jac, label='NeuralIL', ls='-', marker = 's')\n",
    "axs[1].plot(tenserleed_err_jac, label='TensErLEED like expansion', ls='--', marker = 'o')\n",
    "axs[1].legend()\n",
    "axs[1].set_yscale('log')\n",
    "\n",
    "fig.savefig(\"bessel_functions_accuracy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bessel_harmonix(10, 0.0+0j)\n",
    "bessel_harmonix(10, 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bessel_scipy(1e-5+1e-5j, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(121, 121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.rand(121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(((A*b)@A ), np.einsum('ij,j,jk->ik', A, b, A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = jnp.asarray(A)\n",
    "b = jnp.asarray(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def matrix(A,b):\n",
    "    return (A*b)@A\n",
    "\n",
    "@jax.jit\n",
    "def ijjjk(A,b):\n",
    "    return jnp.einsum('ij,j,jk->ik', A, b, A, optimize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time matrix(A,b)\n",
    "%time ijjjk(A,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 10000 matrix(A,b)\n",
    "%timeit -n 10000 ijjjk(A,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(ijjjk(A,b), matrix(A,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_install",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
